Viktor Riabtsev
997544420

First thing to note is that the loop order was switched. The final solution consists of two parts.  For dimensions less or equal than 512, a 32x32 tiling performed the most successfully. Note the first integer (int1) and second (int2) in the int1xint2 tiling indicates the outer and inner loop block sizes respectively. For larger dimensions, coincidentally ones with the most drastic speedups, a 256x16 tiling, combined with a +=4 loop unrolling performed on the outer (256) loop performed the best.
For the smaller dimensions, I suspect most of these smaller "square" blocks end up in the cache, i.e. a large fraction of the image is actually in the cache, and thus both retrieving and writing ends up speeding up. Unrolling here actually slows down the performance, for which I can only guess that you end up with more benefits from the blocking than instruction parrallelism (which may not offer speedups). For the large dimensions, when only smaller fractions of the whole image are in the cache, you end up winning on the perallelism, where cache reads support it. In the end of the day, one must recognize that this personal "best" solution is fitted to the algorithm and for this particular cache system.
