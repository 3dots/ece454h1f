ECE454H1F Computer Systems Programming
Lab 4

By: 	Viktor Riabtsev
		997544420
		
Q1.
Well, program size for one. But really, in the case of global lock vs list lock versions for example, we'd get conflicting code. We'de be intializing structures we don't need to, as well as invoking functions that would slow us down.

Q2.
If this is a round about way of pointing out that using transactional memory was, code-wise, a lot simpler, then I agree.

Q3.
No. The whole concept of "list-level" implies you have looked into the structural implementation. Besides, deciding which list is affected, and then calling to modify it, all happen inside the hash implementation.

Q4.
No. You need to initialize the mutex locks, and while in our case the number of mutexes is fixed, the implmentation actually expects a size parameter during setup, which we need to accomodate dynamically. Similiarly, after we are done with the hash structures, we need to clean them up (which noone ever does in the original implementation), and most importantly, accoriding to the api, an initialized mutex must be "destroyed", thus we need to affect the clean up function as well. 

Q5.
If by this one function you mean uniting all the operations that need to be atomic, and then locking a particular list when it is decided on, and then doing the necessary operations: finding the requested sample and incrementing it, or inserting a new one if not found and intializing the count to 1; followed by unlocking that list... then sure, yeah that will work.

Q6.
Whatever floats your boat. If you want to write a function that locks/unlocks a particular list at index i, instead of just locking/unlocking it then and there, sure.

In the end, the way I implemented the list_lock version was by uniting all the atomic code into a lookup_and_insert_if_absent(Keytype key) call to the hash class. Inside there, all the thread safety (locking) operations happen. It is important to note that the setup and cleanup functions were changed as well, since we added to the actual data structure by adding an array of mutexes.

For the element version, I used the pthread_rwlock_t mutex api because a: it's also in the pthread.h, and b: noone said I can't. This way I avoided any headaches associated with the special case of the element with that key not existing. Normal operation only asks for a reader lock, whereas if a new element has to be inserted, you give up your reader lock and ask for a writer lock. Once you have it, double check the element is still missing, then add, initialize and leave. I had to modify the element class, in this case: the sample class to include a normal mutex lock, which is initialized in the constructor. A destructor had to be added, so that the mutex is destroyed properly during cleanup.

Q7.
Refer to Q2.

Q8
Pros: Don't have to worry about thread synchronization or any race conditions. Cons: Need to allocate more memory for each induvidual thread to use, instead of the single struture.


Timing results for samples_to_skip = 50. Note: each elapsed time is an average of 5 runs.

+------------------------+----------+------------------+
| samples_to_skip = 50   | Thread # | Elapsed time [s] |
+------------------------+----------+------------------+
| randtrack              |          | 17.70            |
+------------------------+----------+------------------+
| randtrack_global_lock  | 1        | 19.37            |
+------------------------+----------+------------------+
|                        | 2        | 14.51            |
+------------------------+----------+------------------+
|                        | 4        | 20.93            |
+------------------------+----------+------------------+
| randtrack_tm           | 1        | 20.94            |
+------------------------+----------+------------------+
|                        | 2        | 21.87            |
+------------------------+----------+------------------+
|                        | 4        | 13.80            |
+------------------------+----------+------------------+
| randtrack_list_lock    | 1        | 19.81            |
+------------------------+----------+------------------+
|                        | 2        | 10.69            |
+------------------------+----------+------------------+
|                        | 4        | 6.77             |
+------------------------+----------+------------------+
| randtrack_element_lock | 1        | 22.45            |
+------------------------+----------+------------------+
|                        | 2        | 12.14            |
+------------------------+----------+------------------+
|                        | 4        | 8.24             |
+------------------------+----------+------------------+
| randtrack_reduction    | 1        | 17.71            |
+------------------------+----------+------------------+
|                        | 2        | 8.94             |
+------------------------+----------+------------------+
|                        | 4        | 4.52             |
+------------------------+----------+------------------+

Q9.

Overhead table:

+------------------------+-----------+
|                        | Ovearhead |
+------------------------+-----------+
| randtrack_global_lock  | 1.09      |
+------------------------+-----------+
| randtrack_tm           | 1.18      |
+------------------------+-----------+
| randtrack_list_lock    | 1.12      |
+------------------------+-----------+
| randtrack_element_lock | 1.27      |
+------------------------+-----------+
| randtrack_reduction    | 1.00      |
+------------------------+-----------+

Q10.

randtrack_global_lock:
The single thread version has some overhead. For two threads, the system speeds up somewhat, however for 4 threads, we actually perform slower that with one. This must be because at 4 threads, they start blocking each far too much.

randtrack_tm:
Quite a bit of overhead. For only two threads, we actually get a slower result than for one. I can only speculate that the implementation of this transactional memory was aimed at more threads, as can be inferred from the much faster result at four threads.

randtrack_list_lock:
A bit of overhead. As thread # rises, speeds up significantly. Actually, this is the fastest multi-threaded version that invloves the synchronised data structure.

randtrack_element_lock:
Largest overhead. Speeds up as thread # rises, although not as effectivly as the list_lock. This is most likely due to the fact that these "lists" into which a sample may fall in, aren't actually all that long. Also, there is a lot of repeated access to the same elements in the list. Thus locking element by element doesnt yield as much benefit, as it would've say if the access there were big lists with a lot off access/changing to many different entries instead of only to a few.

randtrack_reduction:
Almost no overhead. Same speed as original at one thread, not surprisingly. As thread # rises, it speeds up a lot. In fact it has the fastest times for both 2 and 4 threads. The lack of any kind of wait for synchronisation wins you a lot of time, despite having to combine results in the end.

Q11.

Timing results for samples_to_skip = 100. Note: each elapsed time is an average of 5 runs.

+------------------------+----------+------------------+
| samples_to_skip = 100  | Thread # | Elapsed time [s] |
+------------------------+----------+------------------+
| randtrack              |          | 35.04            |
+------------------------+----------+------------------+
| randtrack_global_lock  | 1        | 36.62            |
+------------------------+----------+------------------+
|                        | 2        | 22.46            |
+------------------------+----------+------------------+
|                        | 4        | 19.06            |
+------------------------+----------+------------------+
| randtrack_tm           | 1        | 38.07            |
+------------------------+----------+------------------+
|                        | 2        | 29.86            |
+------------------------+----------+------------------+
|                        | 4        | 16.87            |
+------------------------+----------+------------------+
| randtrack_list_lock    | 1        | 37.19            |
+------------------------+----------+------------------+
|                        | 2        | 19.36            |
+------------------------+----------+------------------+
|                        | 4        | 11.18            |
+------------------------+----------+------------------+
| randtrack_element_lock | 1        | 39.88            |
+------------------------+----------+------------------+
|                        | 2        | 20.82            |
+------------------------+----------+------------------+
|                        | 4        | 12.33            |
+------------------------+----------+------------------+
| randtrack_reduction    | 1        | 35.05            |
+------------------------+----------+------------------+
|                        | 2        | 17.57            |
+------------------------+----------+------------------+
|                        | 4        | 8.92             |
+------------------------+----------+------------------+

Everything takes longer but the patterns of speed up seem to be preserved, except in the case of randtrack_global_lock, where the transition from 2 to 4 now is also a speedup.

Everything is slower because we spend more time twidling our thumbs with the rand_r function between data storage actions.

Because of this, the blockage that randtrack_global_lock expirienced at 4 threads is no longer an issue due to these longer waiting times between data storage.

Q12.

If these testing conditions are indicative of the actual cases that this software will be working on, then I would recommend shipping the randtrack_list_lock version. It benefits from multiple cores very well and doesn't take up extra memory like reduction would. The element_lock version might be more extendable to larger test cases, but since we have such small hash sublists, it is not worth the overhead. The rest simply don't perform that well.


